{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e40191e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from tpot import TPOTClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a45e2f1",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a5c2a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test(df, nsplits, subject_column, label_column):\n",
    "    '''\n",
    "    Creates a train, test split. Each subject is in one of the sets with all his/her data.\n",
    "    Takes a df, number of splits, names of the subject and label column.\n",
    "    Returns 2 dataframes with train and test set.\n",
    "    '''\n",
    "    X = df.drop(columns=[subject_column, label_column])\n",
    "    y = df[[label_column]]\n",
    "    groups = df[subject_column]\n",
    "    \n",
    "    gkf = GroupKFold(n_splits=nsplits)\n",
    "    train_idx, test_idx = next(gkf.split(X, y, groups))\n",
    "\n",
    "    X_train = X.iloc[train_idx.tolist(), :]\n",
    "    y_train = y.iloc[train_idx.tolist(), :]\n",
    "    groups_train = groups.iloc[train_idx.tolist()]\n",
    "    \n",
    "    X_test = X.iloc[test_idx.tolist(), :]\n",
    "    y_test = y.iloc[test_idx.tolist(), :]\n",
    "    groups_test = groups.iloc[test_idx.tolist()]\n",
    "    \n",
    "    res_train = pd.concat([X_train, groups_train, y_train], axis=1)\n",
    "    res_test = pd.concat([X_test, groups_test, y_test], axis=1)\n",
    "    \n",
    "    return res_train, res_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7968d082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_val_test(df, nsplits_val, nplsits_test, subject_column, label_column):\n",
    "    '''\n",
    "    Creates a train, val, test split. Each subject is in one of the sets with all his/her data.\n",
    "    Takes a df, number of splits for train/val split, number of splits for train+val/test split,\n",
    "    names of the subject and label column.\n",
    "    Returns 3 dataframes with train, val, and test set.\n",
    "    '''\n",
    "    # get train_temp and test\n",
    "    res_train_temp, res_test = create_train_test(df, nplsits_test, subject_column, label_column)\n",
    "    \n",
    "    # get train and val from train_temp\n",
    "    res_train, res_val = create_train_test(res_train_temp, nsplits_val, subject_column, label_column)\n",
    "    \n",
    "    return res_train, res_val, res_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31e3bd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df(df, subject_column, label_column):\n",
    "    '''\n",
    "    Takes a df and splits it into three dfs, containing the features, labels, and groups.\n",
    "    '''\n",
    "    X = df.drop(columns=['subject', 'label'])\n",
    "    y = df[['label']]\n",
    "    groups = df['subject']\n",
    "    return X, y, groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6187e4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_correlated_features(df, correlation):\n",
    "    '''\n",
    "    Takes a df and removed the correlated features with a correlation value equal or higher to the given value.\n",
    "    Returns the resulting df and a list of the retained features.\n",
    "    '''\n",
    "    cor = df.corr(numeric_only = True)\n",
    "    keep_columns = np.full(cor.shape[0], True)\n",
    "    for i in range(cor.shape[0] - 1):\n",
    "        for j in range(i + 1, cor.shape[0] - 1):\n",
    "            if (np.abs(cor.iloc[i, j]) >= 0.8):\n",
    "                keep_columns[j] = False\n",
    "    selected_columns = df.columns[keep_columns]\n",
    "    df_reduced = df[selected_columns]\n",
    "    \n",
    "    return df_reduced, selected_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdee9240",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa5ec0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('data-input/flirt-60-1.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbee7d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_mean</th>\n",
       "      <th>x_std</th>\n",
       "      <th>x_min</th>\n",
       "      <th>x_max</th>\n",
       "      <th>x_ptp</th>\n",
       "      <th>x_sum</th>\n",
       "      <th>x_energy</th>\n",
       "      <th>x_skewness</th>\n",
       "      <th>x_kurtosis</th>\n",
       "      <th>x_peaks</th>\n",
       "      <th>...</th>\n",
       "      <th>l2_n_sign_changes</th>\n",
       "      <th>l2_iqr</th>\n",
       "      <th>l2_iqr_5_95</th>\n",
       "      <th>l2_pct_5</th>\n",
       "      <th>l2_pct_95</th>\n",
       "      <th>l2_entropy</th>\n",
       "      <th>l2_perm_entropy</th>\n",
       "      <th>l2_svd_entropy</th>\n",
       "      <th>subject</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-39.333854</td>\n",
       "      <td>21.911315</td>\n",
       "      <td>-119.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>-75521.0</td>\n",
       "      <td>3892335.0</td>\n",
       "      <td>0.667670</td>\n",
       "      <td>1.122428</td>\n",
       "      <td>480</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6.716873</td>\n",
       "      <td>38.096548</td>\n",
       "      <td>49.909418</td>\n",
       "      <td>88.005966</td>\n",
       "      <td>7.546237</td>\n",
       "      <td>0.999670</td>\n",
       "      <td>0.456264</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-39.522917</td>\n",
       "      <td>21.929207</td>\n",
       "      <td>-119.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>-75884.0</td>\n",
       "      <td>3922466.0</td>\n",
       "      <td>0.690015</td>\n",
       "      <td>1.133307</td>\n",
       "      <td>485</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6.711957</td>\n",
       "      <td>38.096548</td>\n",
       "      <td>49.909418</td>\n",
       "      <td>88.005966</td>\n",
       "      <td>7.546232</td>\n",
       "      <td>0.999489</td>\n",
       "      <td>0.456358</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-39.884375</td>\n",
       "      <td>21.849108</td>\n",
       "      <td>-119.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>-76578.0</td>\n",
       "      <td>3970842.0</td>\n",
       "      <td>0.734060</td>\n",
       "      <td>1.226828</td>\n",
       "      <td>490</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6.757474</td>\n",
       "      <td>37.567903</td>\n",
       "      <td>50.438062</td>\n",
       "      <td>88.005966</td>\n",
       "      <td>7.546386</td>\n",
       "      <td>0.999269</td>\n",
       "      <td>0.455761</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-40.117188</td>\n",
       "      <td>21.847705</td>\n",
       "      <td>-119.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>-77025.0</td>\n",
       "      <td>4006485.0</td>\n",
       "      <td>0.754623</td>\n",
       "      <td>1.275292</td>\n",
       "      <td>490</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6.441981</td>\n",
       "      <td>36.429907</td>\n",
       "      <td>50.546513</td>\n",
       "      <td>86.976421</td>\n",
       "      <td>7.546820</td>\n",
       "      <td>0.999406</td>\n",
       "      <td>0.455364</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-40.265625</td>\n",
       "      <td>21.854092</td>\n",
       "      <td>-119.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>-77310.0</td>\n",
       "      <td>4029930.0</td>\n",
       "      <td>0.772855</td>\n",
       "      <td>1.290254</td>\n",
       "      <td>494</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6.300316</td>\n",
       "      <td>35.156783</td>\n",
       "      <td>50.943094</td>\n",
       "      <td>86.099877</td>\n",
       "      <td>7.547107</td>\n",
       "      <td>0.999406</td>\n",
       "      <td>0.452354</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>59.100629</td>\n",
       "      <td>0.877353</td>\n",
       "      <td>56.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9397.0</td>\n",
       "      <td>555491.0</td>\n",
       "      <td>1.088573</td>\n",
       "      <td>8.819387</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.261592</td>\n",
       "      <td>1.994493</td>\n",
       "      <td>61.926548</td>\n",
       "      <td>63.921042</td>\n",
       "      <td>5.068814</td>\n",
       "      <td>0.904938</td>\n",
       "      <td>0.083176</td>\n",
       "      <td>S9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>59.125984</td>\n",
       "      <td>0.980054</td>\n",
       "      <td>56.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7509.0</td>\n",
       "      <td>444099.0</td>\n",
       "      <td>0.900382</td>\n",
       "      <td>6.406320</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.535871</td>\n",
       "      <td>2.331194</td>\n",
       "      <td>61.762448</td>\n",
       "      <td>64.093642</td>\n",
       "      <td>4.844074</td>\n",
       "      <td>0.957356</td>\n",
       "      <td>0.091233</td>\n",
       "      <td>S9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>59.200000</td>\n",
       "      <td>1.110713</td>\n",
       "      <td>56.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5624.0</td>\n",
       "      <td>333058.0</td>\n",
       "      <td>0.660031</td>\n",
       "      <td>4.386405</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.946680</td>\n",
       "      <td>2.588040</td>\n",
       "      <td>61.552431</td>\n",
       "      <td>64.140471</td>\n",
       "      <td>4.553731</td>\n",
       "      <td>0.978071</td>\n",
       "      <td>0.101184</td>\n",
       "      <td>S9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>59.444444</td>\n",
       "      <td>1.192274</td>\n",
       "      <td>56.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3745.0</td>\n",
       "      <td>222709.0</td>\n",
       "      <td>0.496950</td>\n",
       "      <td>4.219449</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.956527</td>\n",
       "      <td>2.421021</td>\n",
       "      <td>61.943523</td>\n",
       "      <td>64.364543</td>\n",
       "      <td>4.142958</td>\n",
       "      <td>0.979869</td>\n",
       "      <td>0.109214</td>\n",
       "      <td>S9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>59.806452</td>\n",
       "      <td>1.305555</td>\n",
       "      <td>56.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1854.0</td>\n",
       "      <td>110934.0</td>\n",
       "      <td>0.621962</td>\n",
       "      <td>4.098393</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.946680</td>\n",
       "      <td>3.894796</td>\n",
       "      <td>61.262024</td>\n",
       "      <td>65.156820</td>\n",
       "      <td>3.433748</td>\n",
       "      <td>0.966619</td>\n",
       "      <td>0.130331</td>\n",
       "      <td>S9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>294559 rows Ã— 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        x_mean      x_std  x_min  x_max  x_ptp    x_sum   x_energy  \\\n",
       "0   -39.333854  21.911315 -119.0   41.0  160.0 -75521.0  3892335.0   \n",
       "1   -39.522917  21.929207 -119.0   41.0  160.0 -75884.0  3922466.0   \n",
       "2   -39.884375  21.849108 -119.0   41.0  160.0 -76578.0  3970842.0   \n",
       "3   -40.117188  21.847705 -119.0   41.0  160.0 -77025.0  4006485.0   \n",
       "4   -40.265625  21.854092 -119.0   41.0  160.0 -77310.0  4029930.0   \n",
       "..         ...        ...    ...    ...    ...      ...        ...   \n",
       "640  59.100629   0.877353   56.0   64.0    8.0   9397.0   555491.0   \n",
       "641  59.125984   0.980054   56.0   64.0    8.0   7509.0   444099.0   \n",
       "642  59.200000   1.110713   56.0   64.0    8.0   5624.0   333058.0   \n",
       "643  59.444444   1.192274   56.0   64.0    8.0   3745.0   222709.0   \n",
       "644  59.806452   1.305555   56.0   64.0    8.0   1854.0   110934.0   \n",
       "\n",
       "     x_skewness  x_kurtosis  x_peaks  ...  l2_n_sign_changes    l2_iqr  \\\n",
       "0      0.667670    1.122428      480  ...                  0  6.716873   \n",
       "1      0.690015    1.133307      485  ...                  0  6.711957   \n",
       "2      0.734060    1.226828      490  ...                  0  6.757474   \n",
       "3      0.754623    1.275292      490  ...                  0  6.441981   \n",
       "4      0.772855    1.290254      494  ...                  0  6.300316   \n",
       "..          ...         ...      ...  ...                ...       ...   \n",
       "640    1.088573    8.819387       17  ...                  0  0.261592   \n",
       "641    0.900382    6.406320       17  ...                  0  0.535871   \n",
       "642    0.660031    4.386405       15  ...                  0  0.946680   \n",
       "643    0.496950    4.219449       10  ...                  0  0.956527   \n",
       "644    0.621962    4.098393        5  ...                  0  0.946680   \n",
       "\n",
       "     l2_iqr_5_95   l2_pct_5  l2_pct_95  l2_entropy  l2_perm_entropy  \\\n",
       "0      38.096548  49.909418  88.005966    7.546237         0.999670   \n",
       "1      38.096548  49.909418  88.005966    7.546232         0.999489   \n",
       "2      37.567903  50.438062  88.005966    7.546386         0.999269   \n",
       "3      36.429907  50.546513  86.976421    7.546820         0.999406   \n",
       "4      35.156783  50.943094  86.099877    7.547107         0.999406   \n",
       "..           ...        ...        ...         ...              ...   \n",
       "640     1.994493  61.926548  63.921042    5.068814         0.904938   \n",
       "641     2.331194  61.762448  64.093642    4.844074         0.957356   \n",
       "642     2.588040  61.552431  64.140471    4.553731         0.978071   \n",
       "643     2.421021  61.943523  64.364543    4.142958         0.979869   \n",
       "644     3.894796  61.262024  65.156820    3.433748         0.966619   \n",
       "\n",
       "     l2_svd_entropy  subject  label  \n",
       "0          0.456264       15      0  \n",
       "1          0.456358       15      0  \n",
       "2          0.455761       15      0  \n",
       "3          0.455364       15      0  \n",
       "4          0.452354       15      0  \n",
       "..              ...      ...    ...  \n",
       "640        0.083176       S9      1  \n",
       "641        0.091233       S9      1  \n",
       "642        0.101184       S9      1  \n",
       "643        0.109214       S9      1  \n",
       "644        0.130331       S9      1  \n",
       "\n",
       "[294559 rows x 90 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a65fed",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9503ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove fixed columns (see EDA)\n",
    "df = df.drop(columns=['l2_n_sign_changes', 'x_entropy', 'y_entropy', 'z_entropy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45b5512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "df_train, df_test = create_train_test(df, 5, 'subject', 'label')\n",
    "\n",
    "X_train, y_train, groups_train = split_df(df_train, 'subject', 'label')\n",
    "X_test, y_test, groups_test = split_df(df_test, 'subject', 'label')\n",
    "\n",
    "# remove correlated features from train\n",
    "X_train, selected_features = remove_correlated_features(X_train, 0.8)\n",
    "\n",
    "# remove the same columns from test\n",
    "X_test = X_test[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d60b5548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage train set: 0.7986583333050424\n",
      "Percentage test set: 0.20134166669495754\n",
      "\n",
      "Class distribution in train set: \n",
      " 1    0.795827\n",
      "0    0.204173\n",
      "Name: label, dtype: float64 \n",
      "\n",
      "Class distribution in test set: \n",
      " 1    0.789097\n",
      "0    0.210903\n",
      "Name: label, dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check train and test set sizes\n",
    "print('Percentage train set:', len(y_train)/(len(y_train)+len(y_test)))\n",
    "print('Percentage test set:', len(y_test)/(len(y_train)+len(y_test)))\n",
    "\n",
    "print('\\nClass distribution in train set: \\n', y_train['label'].value_counts(normalize=True), '\\n')\n",
    "\n",
    "print('Class distribution in test set: \\n', y_test['label'].value_counts(normalize=True), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82789e2f",
   "metadata": {},
   "source": [
    "# TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75efe53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot = TPOTClassifier(generations=5,\n",
    "                      population_size=5,\n",
    "                      scoring='f1',\n",
    "                      cv=5,\n",
    "                      n_jobs=-1,\n",
    "                      verbosity=3,\n",
    "                      random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b683c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 operators have been imported by TPOT.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Tools\\anaconda3\\envs\\stress01\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5841fc8e02b4b098c58e5a4bf55638b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/30 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped pipeline #9 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #11 due to time out. Continuing to the next pipeline.\n",
      "\n",
      "Generation 1 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8863019858646887\tLogisticRegression(input_matrix, LogisticRegression__C=0.0001, LogisticRegression__dual=False, LogisticRegression__penalty=l2)\n",
      "\n",
      "-2\t0.8863072582622928\tLogisticRegression(Binarizer(input_matrix, Binarizer__threshold=0.30000000000000004), LogisticRegression__C=0.0001, LogisticRegression__dual=False, LogisticRegression__penalty=l2)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Skipped pipeline #14 due to time out. Continuing to the next pipeline.\n",
      "\n",
      "Generation 2 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8863019858646887\tLogisticRegression(input_matrix, LogisticRegression__C=0.0001, LogisticRegression__dual=False, LogisticRegression__penalty=l2)\n",
      "\n",
      "-2\t0.8863072582622928\tLogisticRegression(Binarizer(input_matrix, Binarizer__threshold=0.30000000000000004), LogisticRegression__C=0.0001, LogisticRegression__dual=False, LogisticRegression__penalty=l2)\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Skipped pipeline #20 due to time out. Continuing to the next pipeline.\n",
      "\n",
      "Generation 3 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8863019858646887\tLogisticRegression(input_matrix, LogisticRegression__C=0.0001, LogisticRegression__dual=False, LogisticRegression__penalty=l2)\n",
      "\n",
      "-2\t0.8863072582622928\tLogisticRegression(Binarizer(input_matrix, Binarizer__threshold=0.30000000000000004), LogisticRegression__C=0.0001, LogisticRegression__dual=False, LogisticRegression__penalty=l2)\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "Generation 4 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8863019858646887\tLogisticRegression(input_matrix, LogisticRegression__C=0.0001, LogisticRegression__dual=False, LogisticRegression__penalty=l2)\n",
      "\n",
      "-2\t0.8863072582622928\tLogisticRegression(Binarizer(input_matrix, Binarizer__threshold=0.30000000000000004), LogisticRegression__C=0.0001, LogisticRegression__dual=False, LogisticRegression__penalty=l2)\n",
      "\n",
      "Generation 5 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.8863019858646887\tLogisticRegression(input_matrix, LogisticRegression__C=0.0001, LogisticRegression__dual=False, LogisticRegression__penalty=l2)\n",
      "\n",
      "-2\t0.8863072582622928\tLogisticRegression(Binarizer(input_matrix, Binarizer__threshold=0.30000000000000004), LogisticRegression__C=0.0001, LogisticRegression__dual=False, LogisticRegression__penalty=l2)\n",
      "Tpop score on test data: 0.88\n",
      "CPU times: total: 1.05 s\n",
      "Wall time: 21min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tpot.fit(X_train, y_train.values.ravel(), groups=groups_train.values.ravel())\n",
    "print(f\"Tpop score on test data: {tpot.score(X_test, y_test.values.ravel()):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af59570f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPOT score (F1) on test data: 0.88\n"
     ]
    }
   ],
   "source": [
    "print(f\"TPOT score (F1) on test data: {tpot.score(X_test, y_test.values.ravel()):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "379ec20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot.export('tpot_5_5_5_flirt_60_1.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a503a878",
   "metadata": {},
   "source": [
    "# Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ce21d6",
   "metadata": {},
   "source": [
    "I created a TPOT baseline model in this notebook.\n",
    "\n",
    "The data used was created with ```FLIRT``` with a ```window_size``` of ```60``` and a step size of ```1```.\n",
    "\n",
    "The data of each user is either in the train or in the test set. Internally, TPOT does a cross-validation with the training data, and again only uses the data of each user in either training or validation set.\n",
    "\n",
    "Hyperparameters, i.e., aspects that could be changed in future iterations:\n",
    "* Calculating the features with another library instead of FLIRT\n",
    "* Using different window_sizes and step sizes.\n",
    "\n",
    "The results so far are very promising: TPOT returned a pipeline with a Logistic Regression and the performance on the test set is F1=0.88."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (stress01)",
   "language": "python",
   "name": "stress01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "7faeafcdb7b1476f711d2dd1a59a238cf05b963035646615ec88d1898d9d931a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
